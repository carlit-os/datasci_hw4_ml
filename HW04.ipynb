{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Obtain the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = datasets.fetch_california_housing()\n",
    "cal_data=cal.data\n",
    "cal_target=cal.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Regression. (3%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.a Linear model vs. GBT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nsvm_model = SVR(kernel='linear')\\n#linreg_performance = cross_val(5,cal.data,cal.train,svm_model)\\n\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##cross validation k=5\n",
    "##break data into 5 pieces and average performance across these\n",
    "\n",
    "##.fit(trainingvalues,target values)\n",
    "\n",
    "'''\n",
    "def cross_val(folds,train,target,reg):\n",
    "    ## assumes train and target are arrays with same num rows\n",
    "    ## collects model scores and returns averages over folds\n",
    "\n",
    "    step = int(len(train)/folds)\n",
    "    end = step\n",
    "    start = 0\n",
    "    total = 0\n",
    "\n",
    "    for partition in range(folds):\n",
    "        reg.fit(train[start:end],target[start:end])\n",
    "        total += reg.score(train[start:end],target[start:end])\n",
    "\n",
    "        #update range\n",
    "        start = end\n",
    "        end = end + step\n",
    "\n",
    "    return total/folds\n",
    "'''\n",
    "\n",
    "'''\n",
    "svm_model = SVR(kernel='linear')\n",
    "#linreg_performance = cross_val(5,cal.data,cal.train,svm_model)\n",
    "'''\n",
    "#lin_model = sklearn.linear_model.LinearRegression().fit(cal.data,cal.target)\n",
    "#cross_val(5,cal.data,cal.target,sklearn.linear_model.LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a linear regression model, 55.30% of the data fit the model\n",
      "\n",
      "\n",
      "With a gradient boosting tree regression model, 66.99% of the data fit the model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "linreg = sklearn.linear_model.LinearRegression()\n",
    "##fit on the first half of the data\n",
    "\n",
    "half = len(cal_data)//2\n",
    "quarter = len(cal_data)//4\n",
    "threeq = quarter*3\n",
    "\n",
    "\n",
    "linreg.fit(cal_data,cal_target)\n",
    "\n",
    "##score on the second half, use r2 scoring for regression\n",
    "linear_performance = cross_val_score(linreg,cal_data,cal_target, cv=5, scoring='r2').mean()\n",
    "\n",
    "\n",
    "print(\"With a linear regression model, %.2f%% of the data fit the model\"%(linear_performance*100))\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "gbtreg = GradientBoostingRegressor()\n",
    "gbtreg.fit(cal_data,cal_target)\n",
    "gbt_performance = cross_val_score(gbtreg,cal_data,cal_target, cv=5, scoring='r2').mean()\n",
    "\n",
    "print(\"With a gradient boosting tree regression model, %.2f%% of the data fit the model\"%(gbt_performance*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.b Search for better parameters in GBT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss funcitons\n",
      "lad 41.362955921305954\n",
      "huber 39.588201305165796\n",
      "quantile -39.700995382726944\n"
     ]
    }
   ],
   "source": [
    "##Loss functions\n",
    "print(\"Loss funcitons\")\n",
    "gbtreg = GradientBoostingRegressor(loss='lad')\n",
    "gbtreg.fit(cal_data,cal_target)\n",
    "gbt_performance = cross_val_score(gbtreg,cal_data[threeq:],cal_target[threeq:], cv=5, scoring='r2').mean()\n",
    "print(\"lad\",gbt_performance*100)\n",
    "\n",
    "gbtreg = GradientBoostingRegressor(loss='huber')\n",
    "gbtreg.fit(cal_data,cal_target)\n",
    "gbt_performance = cross_val_score(gbtreg,cal_data[threeq:],cal_target[threeq:], cv=5, scoring='r2').mean()\n",
    "print(\"huber\",gbt_performance*100)\n",
    "\n",
    "gbtreg = GradientBoostingRegressor(loss='quantile')\n",
    "gbtreg.fit(cal_data,cal_target)\n",
    "gbt_performance = cross_val_score(gbtreg,cal_data,cal_target, cv=5, scoring='r2').mean()\n",
    "print(\"quantile\",gbt_performance*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{'mean_fit_time': array([0.52866559, 0.7756783 , 0.84914603, 2.11907358, 1.0102078 ,\n",
      "       1.90695443, 1.5002152 , 3.81214452, 1.12298579, 1.72829881,\n",
      "       2.23660517, 5.56480718, 1.28749242, 2.03304191, 3.04795637,\n",
      "       5.65920849, 0.52781248, 0.85498157, 1.04348817, 2.12501626,\n",
      "       0.73259826, 1.18444171, 1.47654781, 3.03627362, 1.42526813,\n",
      "       1.7073205 , 1.97199373, 3.83164692, 1.18611269, 1.8744092 ,\n",
      "       2.68789358, 5.20332241, 0.50249557, 0.78807402, 0.988411  ,\n",
      "       2.10444021, 0.7345314 , 1.15992169, 1.39695659, 2.74923468,\n",
      "       0.91269536, 1.44883399, 1.79226146, 3.61495118, 1.33517547,\n",
      "       2.42726793, 2.69112382, 4.71254826, 0.47900448, 0.93680882,\n",
      "       1.01296115, 2.23046966, 0.83877578, 1.47666206, 1.59478779,\n",
      "       4.29800377, 0.93090911, 1.86262474, 2.17140617, 3.62913327,\n",
      "       1.24949136, 2.21975989, 2.35414834, 4.47773137]), 'std_fit_time': array([0.12385547, 0.18014913, 0.01388024, 0.3363805 , 0.28080623,\n",
      "       0.36209556, 0.10622644, 0.64801151, 0.24235514, 0.12365978,\n",
      "       0.58799192, 0.61649575, 0.01516877, 0.03575597, 0.36308132,\n",
      "       0.63200888, 0.01899847, 0.04543052, 0.01923155, 0.09853943,\n",
      "       0.00568124, 0.02098255, 0.02276051, 0.20819267, 0.22404435,\n",
      "       0.14765526, 0.02838562, 0.07452186, 0.01801732, 0.0214071 ,\n",
      "       0.37523086, 0.44727932, 0.01446839, 0.01545971, 0.02852212,\n",
      "       0.18651693, 0.02735306, 0.02388935, 0.03002656, 0.07073093,\n",
      "       0.02069655, 0.02546135, 0.02495339, 0.10006619, 0.26580207,\n",
      "       0.24780381, 0.39860211, 0.27181692, 0.01024725, 0.14079272,\n",
      "       0.05056941, 0.23836668, 0.11231645, 0.1711509 , 0.16237223,\n",
      "       0.76182551, 0.00958968, 0.27547287, 0.28498807, 0.0780755 ,\n",
      "       0.14398837, 0.26524318, 0.07402517, 0.11891989]), 'mean_score_time': array([0.00284014, 0.00374823, 0.00406284, 0.00728998, 0.00665956,\n",
      "       0.00763898, 0.00586996, 0.01379728, 0.00528021, 0.00802798,\n",
      "       0.00817342, 0.02033877, 0.00646858, 0.00883846, 0.01237164,\n",
      "       0.0212574 , 0.00277157, 0.00384154, 0.00442986, 0.00757103,\n",
      "       0.00378404, 0.00495677, 0.00621591, 0.01392169, 0.00677519,\n",
      "       0.00685897, 0.00761313, 0.01280556, 0.00548058, 0.00780387,\n",
      "       0.01269317, 0.01876602, 0.00249095, 0.00344458, 0.00411477,\n",
      "       0.00767794, 0.00397701, 0.00483642, 0.0055892 , 0.00906634,\n",
      "       0.00372419, 0.00556312, 0.00613284, 0.01162925, 0.00573564,\n",
      "       0.00806704, 0.01054425, 0.01700249, 0.00233979, 0.0042582 ,\n",
      "       0.0041348 , 0.00796404, 0.00415964, 0.00555763, 0.00581694,\n",
      "       0.0124197 , 0.0042232 , 0.00636816, 0.00710621, 0.01285396,\n",
      "       0.006463  , 0.0075676 , 0.00902057, 0.01609478]), 'std_score_time': array([0.00056634, 0.00133441, 0.00038125, 0.00074103, 0.00221409,\n",
      "       0.00077498, 0.0002614 , 0.00310857, 0.0013529 , 0.00075149,\n",
      "       0.00116352, 0.00684604, 0.00088637, 0.00140106, 0.00210583,\n",
      "       0.0034277 , 0.00028923, 0.00033504, 0.00050038, 0.00065555,\n",
      "       0.00043868, 0.00055872, 0.00076127, 0.00590335, 0.00184282,\n",
      "       0.00051962, 0.0006668 , 0.0015178 , 0.00065993, 0.00080264,\n",
      "       0.00519304, 0.00486263, 0.00024824, 0.00041173, 0.00053377,\n",
      "       0.00055087, 0.00050912, 0.0004215 , 0.00056477, 0.00090445,\n",
      "       0.00012156, 0.00057252, 0.00021253, 0.0025775 , 0.00097048,\n",
      "       0.00049949, 0.00230999, 0.00265949, 0.0002294 , 0.00153622,\n",
      "       0.00028488, 0.00104669, 0.00098454, 0.00068997, 0.00112134,\n",
      "       0.00170223, 0.00072281, 0.00086945, 0.00066783, 0.0013281 ,\n",
      "       0.00227687, 0.00066309, 0.00116243, 0.00103658]), 'param_learning_rate': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
      "                   0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
      "                   0.15, 0.15, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.25, 0.25,\n",
      "                   0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
      "                   0.25, 0.25, 0.25, 0.25, 0.25],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 2, 2,\n",
      "                   2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 2, 2, 2, 2,\n",
      "                   3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 2, 2, 2, 2, 3, 3,\n",
      "                   3, 3, 4, 4, 4, 4, 5, 5, 5, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[50, 80, 100, 200, 50, 80, 100, 200, 50, 80, 100, 200,\n",
      "                   50, 80, 100, 200, 50, 80, 100, 200, 50, 80, 100, 200,\n",
      "                   50, 80, 100, 200, 50, 80, 100, 200, 50, 80, 100, 200,\n",
      "                   50, 80, 100, 200, 50, 80, 100, 200, 50, 80, 100, 200,\n",
      "                   50, 80, 100, 200, 50, 80, 100, 200, 50, 80, 100, 200,\n",
      "                   50, 80, 100, 200],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 50}, {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 80}, {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 80}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 50}, {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 80}, {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 80}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 50}, {'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 80}, {'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 50}, {'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 80}, {'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 50}, {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 80}, {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 50}, {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 80}, {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 50}, {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 80}, {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 50}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 80}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 50}, {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 80}, {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 50}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 80}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.25, 'max_depth': 2, 'n_estimators': 50}, {'learning_rate': 0.25, 'max_depth': 2, 'n_estimators': 80}, {'learning_rate': 0.25, 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.25, 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.25, 'max_depth': 3, 'n_estimators': 50}, {'learning_rate': 0.25, 'max_depth': 3, 'n_estimators': 80}, {'learning_rate': 0.25, 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.25, 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.25, 'max_depth': 4, 'n_estimators': 50}, {'learning_rate': 0.25, 'max_depth': 4, 'n_estimators': 80}, {'learning_rate': 0.25, 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.25, 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.25, 'max_depth': 5, 'n_estimators': 50}, {'learning_rate': 0.25, 'max_depth': 5, 'n_estimators': 80}, {'learning_rate': 0.25, 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.25, 'max_depth': 5, 'n_estimators': 200}], 'split0_test_score': array([0.37674918, 0.36678539, 0.39352498, 0.42653929, 0.39366234,\n",
      "       0.43139705, 0.42757448, 0.42928457, 0.42719327, 0.43106211,\n",
      "       0.44091564, 0.43144706, 0.43574108, 0.4310697 , 0.42985875,\n",
      "       0.41952421, 0.37066152, 0.39898794, 0.39971461, 0.43110883,\n",
      "       0.42947855, 0.44761263, 0.44169689, 0.43125879, 0.43436169,\n",
      "       0.4483401 , 0.45166663, 0.44370197, 0.43904619, 0.43468972,\n",
      "       0.42599655, 0.42986263, 0.40293685, 0.40226522, 0.41054218,\n",
      "       0.41358323, 0.43871851, 0.44071974, 0.44717439, 0.43972472,\n",
      "       0.42357342, 0.41724803, 0.42290296, 0.42018272, 0.43037334,\n",
      "       0.42931198, 0.4211839 , 0.41821792, 0.39753623, 0.41652642,\n",
      "       0.41645834, 0.41508815, 0.42303665, 0.43717414, 0.43128573,\n",
      "       0.42505751, 0.44870577, 0.42971563, 0.42890349, 0.41177482,\n",
      "       0.41464255, 0.41682483, 0.41167727, 0.39180471]), 'split1_test_score': array([0.55018513, 0.58276952, 0.58665459, 0.58877276, 0.59146202,\n",
      "       0.60434362, 0.60332005, 0.61069767, 0.60618984, 0.60786077,\n",
      "       0.60912367, 0.60947706, 0.61515472, 0.61236795, 0.61101725,\n",
      "       0.60536423, 0.57979305, 0.58767834, 0.58699421, 0.59051166,\n",
      "       0.60418349, 0.60935987, 0.60884017, 0.60899162, 0.60714531,\n",
      "       0.60800489, 0.60755107, 0.60540177, 0.61020881, 0.6113597 ,\n",
      "       0.60718869, 0.59774736, 0.58753747, 0.5931277 , 0.59348762,\n",
      "       0.59161853, 0.60374176, 0.60898563, 0.60856764, 0.60897877,\n",
      "       0.60927297, 0.6067133 , 0.60472104, 0.59819525, 0.61184252,\n",
      "       0.60838251, 0.60765442, 0.59992291, 0.58517795, 0.58343438,\n",
      "       0.5857823 , 0.59076205, 0.60987854, 0.60867015, 0.60665413,\n",
      "       0.60385563, 0.60592101, 0.60994094, 0.60303274, 0.58858314,\n",
      "       0.59481069, 0.59006634, 0.58772141, 0.57776054]), 'split2_test_score': array([0.56412151, 0.58960447, 0.59375334, 0.60105485, 0.60316283,\n",
      "       0.61211408, 0.61450694, 0.61929713, 0.62073458, 0.62592884,\n",
      "       0.62754838, 0.63152716, 0.63161567, 0.63455876, 0.63631989,\n",
      "       0.63397624, 0.5937753 , 0.60351602, 0.60424223, 0.61217175,\n",
      "       0.60991299, 0.61428197, 0.61583653, 0.62475105, 0.62254166,\n",
      "       0.62486392, 0.62533605, 0.62643464, 0.62581212, 0.62884938,\n",
      "       0.62853691, 0.62595675, 0.59427002, 0.60137028, 0.6031706 ,\n",
      "       0.61030188, 0.61752614, 0.62085923, 0.62180564, 0.62616851,\n",
      "       0.62856523, 0.62769047, 0.62895189, 0.62727972, 0.63251322,\n",
      "       0.63357435, 0.63314741, 0.62859003, 0.60354624, 0.60740399,\n",
      "       0.60859184, 0.61557724, 0.61559808, 0.62172838, 0.62463913,\n",
      "       0.62437473, 0.62666584, 0.62774942, 0.62618482, 0.62415806,\n",
      "       0.63283707, 0.63019456, 0.62764545, 0.62230465]), 'split3_test_score': array([0.39268613, 0.45338547, 0.47066757, 0.50072305, 0.46701345,\n",
      "       0.50650852, 0.51611857, 0.52297469, 0.49222163, 0.51960613,\n",
      "       0.52249301, 0.52413409, 0.51251792, 0.52347616, 0.52674861,\n",
      "       0.52530316, 0.44995039, 0.47788533, 0.48855432, 0.50508553,\n",
      "       0.49882619, 0.51204435, 0.5146877 , 0.51525277, 0.51404667,\n",
      "       0.52562701, 0.52482412, 0.5180585 , 0.51717985, 0.51956576,\n",
      "       0.51885743, 0.51848021, 0.45704986, 0.48385011, 0.48609036,\n",
      "       0.51226653, 0.51639108, 0.52496867, 0.52721862, 0.52908206,\n",
      "       0.52037785, 0.5256178 , 0.52552124, 0.51412603, 0.52598556,\n",
      "       0.52806275, 0.52803373, 0.51330601, 0.47734203, 0.48631274,\n",
      "       0.49587255, 0.5157971 , 0.51641942, 0.52243747, 0.52402176,\n",
      "       0.51598331, 0.52639774, 0.52663675, 0.52749199, 0.52453101,\n",
      "       0.51589103, 0.51498073, 0.51491765, 0.49549545]), 'split4_test_score': array([0.59445687, 0.62345823, 0.62868085, 0.64775981, 0.62041651,\n",
      "       0.63892153, 0.64412605, 0.64358515, 0.6396375 , 0.64275241,\n",
      "       0.64262802, 0.62511842, 0.63082257, 0.63356042, 0.62664199,\n",
      "       0.61156589, 0.62865711, 0.64435383, 0.64743777, 0.64703892,\n",
      "       0.64387227, 0.64547409, 0.64516857, 0.63928562, 0.64944768,\n",
      "       0.64700908, 0.64185606, 0.61143592, 0.63549254, 0.62377714,\n",
      "       0.62236992, 0.59668868, 0.63298367, 0.64044859, 0.64206135,\n",
      "       0.64256207, 0.64422125, 0.63673418, 0.63594204, 0.61743668,\n",
      "       0.63893377, 0.62909113, 0.62810347, 0.59214887, 0.63446458,\n",
      "       0.61707687, 0.60709623, 0.57113973, 0.65076698, 0.64778951,\n",
      "       0.64822664, 0.63923596, 0.63927738, 0.64056943, 0.63969203,\n",
      "       0.61559189, 0.63219539, 0.63035405, 0.62613793, 0.58037584,\n",
      "       0.61715078, 0.59798368, 0.58802034, 0.55224006]), 'mean_test_score': array([0.49563976, 0.52320061, 0.53465626, 0.55296995, 0.53514343,\n",
      "       0.55865696, 0.56112922, 0.56516784, 0.55719536, 0.56544205,\n",
      "       0.56854174, 0.56434076, 0.56517039, 0.5670066 , 0.5661173 ,\n",
      "       0.55914675, 0.52456747, 0.54248429, 0.54538863, 0.55718334,\n",
      "       0.5572547 , 0.56575458, 0.56524597, 0.56390797, 0.5655086 ,\n",
      "       0.570769  , 0.57024679, 0.56100656, 0.5655479 , 0.56364834,\n",
      "       0.5605899 , 0.55374712, 0.53495558, 0.54421238, 0.54707042,\n",
      "       0.55406645, 0.56411975, 0.56645349, 0.56814167, 0.56427815,\n",
      "       0.56414465, 0.56127214, 0.56204012, 0.55038652, 0.56703584,\n",
      "       0.56328169, 0.55942314, 0.54623532, 0.54287389, 0.54829341,\n",
      "       0.55098633, 0.5552921 , 0.56084201, 0.56611591, 0.56525856,\n",
      "       0.55697261, 0.56797715, 0.56487936, 0.5623502 , 0.54588457,\n",
      "       0.55506642, 0.55001003, 0.54599642, 0.52792108]), 'std_test_score': array([0.09183048, 0.0973133 , 0.08837365, 0.07911203, 0.08913867,\n",
      "       0.07784841, 0.0792219 , 0.07924234, 0.08289333, 0.07949062,\n",
      "       0.07619234, 0.07684079, 0.07841919, 0.07927685, 0.07838869,\n",
      "       0.07889628, 0.09790709, 0.09045331, 0.08950962, 0.07850795,\n",
      "       0.08027259, 0.07409971, 0.07572053, 0.07922037, 0.07984985,\n",
      "       0.07369119, 0.07166421, 0.0698567 , 0.0759747 , 0.07578472,\n",
      "       0.0780538 , 0.0715337 , 0.08875901, 0.08799289, 0.08565465,\n",
      "       0.08232475, 0.07594984, 0.07380828, 0.07130042, 0.07128354,\n",
      "       0.0817995 , 0.08135095, 0.0791909 , 0.0751135 , 0.07899788,\n",
      "       0.07623296, 0.07762684, 0.07450863, 0.09222705, 0.08465526,\n",
      "       0.08380947, 0.08143217, 0.08064565, 0.07613242, 0.07801177,\n",
      "       0.07649706, 0.07065775, 0.07746206, 0.07592354, 0.07427106,\n",
      "       0.08091468, 0.0765518 , 0.07639512, 0.07945153]), 'rank_test_score': array([64, 63, 60, 45, 58, 36, 30, 18, 38, 14,  3, 20, 17,  7,  9, 35, 62,\n",
      "       57, 54, 39, 37, 11, 16, 24, 13,  1,  2, 31, 12, 25, 33, 44, 59, 55,\n",
      "       50, 43, 23,  8,  4, 21, 22, 29, 28, 47,  6, 26, 34, 51, 56, 49, 46,\n",
      "       41, 32, 10, 15, 40,  5, 19, 27, 53, 42, 48, 52, 61], dtype=int32)}\n",
      "\n",
      "\n",
      "0.5707689994618337\n",
      "\n",
      "{'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 80}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\")\n",
    "parameters={'learning_rate':[.1,.15,.2,.25],'max_depth':[2,3,4,5],'n_estimators':[50,80,100,200]}\n",
    "gs_model=GridSearchCV(GradientBoostingRegressor(),parameters,scoring=\"r2\",cv=5)\n",
    "gs_model.fit(cal_data,cal_target)\n",
    "print(\"\")\n",
    "print(gs_model.cv_results_)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(gs_model.best_score_)\n",
    "print(\"\")\n",
    "print(gs_model.best_params_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Classification. (3%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.a Logistic regression vs. GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Python/3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Python/3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Python/3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Python/3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Python/3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3315891472868217\n",
      "0.4775193798449612\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(cal_data,cal_target)\n",
    "\n",
    "##score on the second half, use r2 scoring for regression\n",
    "logistic_performance = cross_val_score(logreg,cal_data,cal_target, cv=5, scoring='accuracy').mean()\n",
    "print(logistic_performance)\n",
    "\n",
    "gbt_class=GradientBoostingClassifier()\n",
    "gbt_class.fit(cal_data,cal_target)\n",
    "gbt_class_performance = cross_val_score(gbt_class,cal_data,cal_target, cv=5, scoring='accuracy').mean()\n",
    "print(gbt_class_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.b Search for optimal parameters in GBT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mean_fit_time': array([0.42859445, 0.69167557, 1.09979954, 2.2021852 , 0.44045162,\n",
      "       0.70576477, 0.86338143, 1.64140291, 0.51912584, 0.81554012,\n",
      "       1.0017776 , 2.01968927, 0.65139055, 1.03035469, 1.27243147,\n",
      "       2.74220223, 0.28842974, 0.48111539, 0.58772774, 1.15545139,\n",
      "       0.38075228, 0.59952354, 0.74621882, 1.51103702, 0.48272433,\n",
      "       0.76430655, 1.01574636, 1.93546066, 0.63897114, 1.01782656,\n",
      "       1.26119928, 2.48465867, 0.3061244 , 0.4643302 , 0.5497273 ,\n",
      "       1.21007047, 0.617134  , 0.94901762, 0.96318679, 1.88964958,\n",
      "       0.50990911, 0.80848117, 1.01208835, 1.99640646, 0.65645003,\n",
      "       1.05007463, 1.28879457, 2.55245924, 0.29775167, 0.47868176,\n",
      "       0.57618623, 1.1512722 , 0.37542439, 0.60116963, 0.74851704,\n",
      "       1.50619235, 0.48376689, 0.77112575, 0.94825459, 1.8875298 ,\n",
      "       0.61022391, 0.98803415, 1.23419838, 2.42344995]), 'std_fit_time': array([0.12493532, 0.06637313, 0.18444186, 0.52943857, 0.00461085,\n",
      "       0.03477019, 0.02894135, 0.05285437, 0.0080217 , 0.0173518 ,\n",
      "       0.0167001 , 0.08362846, 0.01179251, 0.03193271, 0.02738131,\n",
      "       0.47359565, 0.01169758, 0.01789694, 0.01823089, 0.01092762,\n",
      "       0.01819263, 0.01925151, 0.02441855, 0.03393326, 0.01020784,\n",
      "       0.02028312, 0.05663963, 0.03741502, 0.01926055, 0.03967746,\n",
      "       0.03005761, 0.02859078, 0.02321664, 0.01258915, 0.00787033,\n",
      "       0.0458408 , 0.15645282, 0.18088336, 0.20308963, 0.43555732,\n",
      "       0.01469037, 0.0160169 , 0.01457618, 0.02128082, 0.02532841,\n",
      "       0.01399768, 0.02322218, 0.04076687, 0.01751896, 0.02561857,\n",
      "       0.01067662, 0.02306838, 0.01179732, 0.00509432, 0.0325509 ,\n",
      "       0.0272477 , 0.01163925, 0.01076077, 0.00374778, 0.02242878,\n",
      "       0.01526213, 0.02367527, 0.02154873, 0.03207186]), 'mean_score_time': array([0.00175781, 0.00197473, 0.00436444, 0.00587506, 0.00201397,\n",
      "       0.00268717, 0.0027441 , 0.00455904, 0.00211401, 0.00283742,\n",
      "       0.0036252 , 0.00567675, 0.00250535, 0.00328407, 0.00414009,\n",
      "       0.00663514, 0.00116425, 0.00161657, 0.00190091, 0.00291839,\n",
      "       0.00170674, 0.0020659 , 0.00245166, 0.00416703, 0.0018168 ,\n",
      "       0.00284157, 0.00343533, 0.00570655, 0.00265369, 0.00333247,\n",
      "       0.00388565, 0.00705609, 0.00128698, 0.00165658, 0.00177455,\n",
      "       0.0034771 , 0.00249095, 0.0035058 , 0.00271778, 0.00507503,\n",
      "       0.00213981, 0.00297074, 0.00313778, 0.00569758, 0.00231886,\n",
      "       0.00369248, 0.00425372, 0.00723691, 0.00131483, 0.00186973,\n",
      "       0.00180459, 0.00326476, 0.00159488, 0.00209866, 0.00238919,\n",
      "       0.00389142, 0.00208688, 0.00276518, 0.00312119, 0.00598021,\n",
      "       0.00221496, 0.00324254, 0.00417528, 0.00735269]), 'std_score_time': array([5.17565329e-04, 2.82722119e-04, 2.14587649e-03, 3.45007371e-03,\n",
      "       3.92098194e-04, 4.10917984e-04, 9.91479191e-05, 4.79520282e-04,\n",
      "       1.33092110e-04, 3.25576820e-04, 2.17112289e-05, 9.00602367e-04,\n",
      "       1.38417162e-04, 3.81347356e-04, 3.23618050e-04, 4.04083281e-04,\n",
      "       7.79422972e-05, 1.21245035e-04, 2.12720044e-04, 1.86068959e-04,\n",
      "       1.85350817e-04, 2.91156980e-04, 1.88876095e-04, 2.39078676e-04,\n",
      "       1.77965274e-04, 3.21973239e-04, 4.94547962e-04, 7.49289293e-04,\n",
      "       3.22282189e-04, 3.16122272e-04, 2.30027382e-04, 5.29168661e-04,\n",
      "       1.57173802e-04, 2.22498952e-04, 1.94010326e-04, 5.93288526e-04,\n",
      "       6.55555326e-04, 7.16716461e-04, 2.43537099e-04, 7.09594870e-04,\n",
      "       1.61911811e-04, 1.72789983e-04, 1.67893097e-04, 3.59954406e-04,\n",
      "       2.57582340e-04, 5.65871007e-04, 5.30802064e-04, 1.07584973e-03,\n",
      "       1.58077480e-04, 4.05769650e-05, 1.62870570e-04, 3.97021089e-04,\n",
      "       1.42599075e-04, 2.67646221e-04, 2.49509389e-04, 1.85584777e-04,\n",
      "       2.47770938e-04, 2.73762590e-04, 3.12459765e-04, 4.77314958e-04,\n",
      "       3.05098375e-04, 4.87841943e-04, 3.04549536e-04, 6.86578615e-05]), 'param_learning_rate': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
      "                   0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
      "                   0.15, 0.15, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.25, 0.25,\n",
      "                   0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
      "                   0.25, 0.25, 0.25, 0.25, 0.25],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 2, 2,\n",
      "                   2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 2, 2, 2, 2,\n",
      "                   3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 2, 2, 2, 2, 3, 3,\n",
      "                   3, 3, 4, 4, 4, 4, 5, 5, 5, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[50, 80, 100, 200, 50, 80, 100, 200, 50, 80, 100, 200,\n",
      "                   50, 80, 100, 200, 50, 80, 100, 200, 50, 80, 100, 200,\n",
      "                   50, 80, 100, 200, 50, 80, 100, 200, 50, 80, 100, 200,\n",
      "                   50, 80, 100, 200, 50, 80, 100, 200, 50, 80, 100, 200,\n",
      "                   50, 80, 100, 200, 50, 80, 100, 200, 50, 80, 100, 200,\n",
      "                   50, 80, 100, 200],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 50}, {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 80}, {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 80}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 50}, {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 80}, {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 80}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 50}, {'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 80}, {'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 50}, {'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 80}, {'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 50}, {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 80}, {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 50}, {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 80}, {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 50}, {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 80}, {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 50}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 80}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 50}, {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 80}, {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 50}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 80}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.25, 'max_depth': 2, 'n_estimators': 50}, {'learning_rate': 0.25, 'max_depth': 2, 'n_estimators': 80}, {'learning_rate': 0.25, 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.25, 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.25, 'max_depth': 3, 'n_estimators': 50}, {'learning_rate': 0.25, 'max_depth': 3, 'n_estimators': 80}, {'learning_rate': 0.25, 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.25, 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.25, 'max_depth': 4, 'n_estimators': 50}, {'learning_rate': 0.25, 'max_depth': 4, 'n_estimators': 80}, {'learning_rate': 0.25, 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.25, 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.25, 'max_depth': 5, 'n_estimators': 50}, {'learning_rate': 0.25, 'max_depth': 5, 'n_estimators': 80}, {'learning_rate': 0.25, 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.25, 'max_depth': 5, 'n_estimators': 200}], 'split0_test_score': array([0.525, 0.52 , 0.525, 0.5  , 0.545, 0.55 , 0.535, 0.51 , 0.535,\n",
      "       0.525, 0.515, 0.52 , 0.525, 0.52 , 0.535, 0.5  , 0.515, 0.515,\n",
      "       0.51 , 0.52 , 0.55 , 0.525, 0.51 , 0.495, 0.515, 0.525, 0.52 ,\n",
      "       0.51 , 0.55 , 0.51 , 0.515, 0.48 , 0.495, 0.5  , 0.485, 0.49 ,\n",
      "       0.555, 0.505, 0.495, 0.485, 0.54 , 0.5  , 0.505, 0.515, 0.505,\n",
      "       0.5  , 0.51 , 0.52 , 0.51 , 0.505, 0.495, 0.5  , 0.54 , 0.515,\n",
      "       0.495, 0.49 , 0.52 , 0.485, 0.53 , 0.505, 0.5  , 0.49 , 0.505,\n",
      "       0.5  ]), 'split1_test_score': array([0.515, 0.5  , 0.52 , 0.54 , 0.5  , 0.495, 0.52 , 0.495, 0.495,\n",
      "       0.5  , 0.495, 0.505, 0.52 , 0.51 , 0.515, 0.52 , 0.515, 0.52 ,\n",
      "       0.535, 0.525, 0.5  , 0.515, 0.505, 0.51 , 0.495, 0.515, 0.505,\n",
      "       0.5  , 0.5  , 0.505, 0.525, 0.48 , 0.465, 0.505, 0.52 , 0.55 ,\n",
      "       0.52 , 0.495, 0.5  , 0.5  , 0.505, 0.515, 0.505, 0.5  , 0.525,\n",
      "       0.505, 0.515, 0.5  , 0.49 , 0.52 , 0.53 , 0.53 , 0.51 , 0.515,\n",
      "       0.515, 0.505, 0.495, 0.5  , 0.48 , 0.49 , 0.515, 0.48 , 0.51 ,\n",
      "       0.485]), 'split2_test_score': array([0.53 , 0.535, 0.535, 0.535, 0.565, 0.545, 0.575, 0.515, 0.52 ,\n",
      "       0.51 , 0.505, 0.475, 0.485, 0.47 , 0.485, 0.47 , 0.52 , 0.55 ,\n",
      "       0.56 , 0.54 , 0.52 , 0.53 , 0.515, 0.49 , 0.535, 0.495, 0.495,\n",
      "       0.485, 0.47 , 0.475, 0.445, 0.455, 0.55 , 0.56 , 0.55 , 0.54 ,\n",
      "       0.53 , 0.505, 0.505, 0.48 , 0.485, 0.505, 0.495, 0.46 , 0.51 ,\n",
      "       0.46 , 0.465, 0.455, 0.54 , 0.56 , 0.53 , 0.51 , 0.525, 0.505,\n",
      "       0.505, 0.47 , 0.47 , 0.535, 0.485, 0.48 , 0.475, 0.48 , 0.46 ,\n",
      "       0.425]), 'split3_test_score': array([0.61 , 0.615, 0.63 , 0.64 , 0.585, 0.59 , 0.6  , 0.64 , 0.61 ,\n",
      "       0.62 , 0.615, 0.595, 0.585, 0.58 , 0.575, 0.565, 0.61 , 0.63 ,\n",
      "       0.64 , 0.61 , 0.615, 0.6  , 0.63 , 0.59 , 0.625, 0.61 , 0.585,\n",
      "       0.595, 0.59 , 0.545, 0.555, 0.555, 0.62 , 0.64 , 0.645, 0.62 ,\n",
      "       0.61 , 0.6  , 0.595, 0.585, 0.585, 0.595, 0.605, 0.59 , 0.575,\n",
      "       0.565, 0.57 , 0.565, 0.65 , 0.64 , 0.64 , 0.62 , 0.605, 0.62 ,\n",
      "       0.61 , 0.595, 0.57 , 0.575, 0.565, 0.565, 0.545, 0.595, 0.58 ,\n",
      "       0.55 ]), 'split4_test_score': array([0.53 , 0.535, 0.535, 0.525, 0.53 , 0.535, 0.535, 0.57 , 0.535,\n",
      "       0.54 , 0.52 , 0.525, 0.54 , 0.52 , 0.495, 0.52 , 0.52 , 0.53 ,\n",
      "       0.545, 0.55 , 0.5  , 0.535, 0.55 , 0.575, 0.53 , 0.545, 0.53 ,\n",
      "       0.53 , 0.51 , 0.52 , 0.52 , 0.52 , 0.55 , 0.54 , 0.56 , 0.575,\n",
      "       0.535, 0.555, 0.545, 0.575, 0.565, 0.55 , 0.53 , 0.55 , 0.52 ,\n",
      "       0.5  , 0.515, 0.525, 0.52 , 0.545, 0.54 , 0.555, 0.565, 0.58 ,\n",
      "       0.56 , 0.59 , 0.54 , 0.54 , 0.54 , 0.55 , 0.55 , 0.545, 0.555,\n",
      "       0.545]), 'mean_test_score': array([0.542, 0.541, 0.549, 0.548, 0.545, 0.543, 0.553, 0.546, 0.539,\n",
      "       0.539, 0.53 , 0.524, 0.531, 0.52 , 0.521, 0.515, 0.536, 0.549,\n",
      "       0.558, 0.549, 0.537, 0.541, 0.542, 0.532, 0.54 , 0.538, 0.527,\n",
      "       0.524, 0.524, 0.511, 0.512, 0.498, 0.536, 0.549, 0.552, 0.555,\n",
      "       0.55 , 0.532, 0.528, 0.525, 0.536, 0.533, 0.528, 0.523, 0.527,\n",
      "       0.506, 0.515, 0.513, 0.542, 0.554, 0.547, 0.543, 0.549, 0.547,\n",
      "       0.537, 0.53 , 0.519, 0.527, 0.52 , 0.518, 0.517, 0.518, 0.522,\n",
      "       0.501]), 'std_test_score': array([0.03443835, 0.03916631, 0.04091455, 0.04802083, 0.02915476,\n",
      "       0.03043025, 0.02976575, 0.05342284, 0.03839271, 0.04270831,\n",
      "       0.04335897, 0.03954744, 0.03246537, 0.03521363, 0.032     ,\n",
      "       0.03098387, 0.03706751, 0.04223742, 0.04411349, 0.03231099,\n",
      "       0.04308132, 0.03023243, 0.04675468, 0.0420238 , 0.04472136,\n",
      "       0.03944617, 0.03140064, 0.03839271, 0.04176123, 0.02267157,\n",
      "       0.03627671, 0.03529873, 0.05323533, 0.05063596, 0.05334791,\n",
      "       0.04266146, 0.03209361, 0.03994997, 0.03789459, 0.04549725,\n",
      "       0.03693237, 0.03558089, 0.0401995 , 0.04422669, 0.02501999,\n",
      "       0.03367492, 0.03331666, 0.03586084, 0.05635601, 0.04705316,\n",
      "       0.04894895, 0.04284857, 0.03337664, 0.04523273, 0.04273172,\n",
      "       0.0522494 , 0.0346987 , 0.0317175 , 0.03271085, 0.03355592,\n",
      "       0.02803569, 0.04545327, 0.04178516, 0.04554119]), 'rank_test_score': array([19, 22,  7, 12, 16, 18,  4, 15, 25, 26, 37, 47, 36, 51, 50, 58, 30,\n",
      "        7,  1,  7, 28, 22, 19, 34, 24, 27, 42, 45, 45, 61, 60, 64, 31,  7,\n",
      "        5,  2,  6, 34, 39, 44, 31, 33, 39, 48, 41, 62, 57, 59, 19,  3, 14,\n",
      "       17,  7, 13, 28, 38, 53, 42, 51, 54, 56, 54, 49, 63], dtype=int32)}\n",
      "\n",
      "\n",
      "0.558\n",
      "\n",
      "{'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "parameters={'learning_rate':[.1,.15,.2,.25],'max_depth':[2,3,4,5],'n_estimators':[50,80,100,200]}\n",
    "gs_model=GridSearchCV(GradientBoostingClassifier(),parameters,scoring=\"accuracy\",cv=5)\n",
    "gs_model.fit(cal_data[:1000],cal_target[:1000])\n",
    "print(\"\")\n",
    "print(gs_model.cv_results_)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(gs_model.best_score_)\n",
    "print(\"\")\n",
    "print(gs_model.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.c SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parameters={'C':[100,1000,200,300]}\n",
    "gs_model=GridSearchCV(SVC(kernel='linear'),parameters,scoring=\"roc_auc\",cv=5)\n",
    "gs_model.fit(cal_data[:1000],cal_target[:1000])\n",
    "print(\"\")\n",
    "print(gs_model.cv_results_)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(gs_model.best_score_)\n",
    "print(\"\")\n",
    "print(gs_model.best_params_)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}